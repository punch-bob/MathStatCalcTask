{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MathStatCalcTask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJOnmmC/jqnn/cZ4B2vZ7V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punch-bob/MathStatCalcTask/blob/main/MathStatCalcTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$\\text{First:}$"
      ],
      "metadata": {
        "id": "oLILXf8KnYgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install ipympl # uncomment at first launch"
      ],
      "metadata": {
        "id": "NH5ukJFyDuyX"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "dmgoVHtUgmuv"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "R76YbRnY-MvS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from scipy.stats import norm\n",
        "from scipy.stats.distributions import chi2, t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1Data = [-1.135, -0.592, -0.766, -1.177, -0.735, -1.717, 0.336, -1.140, -0.155, -2.048,\n",
        "             -1.137, -2.147, -0.313, -0.056, -0.286, -0.829, -0.290, -0.639, -1.397, 0.362,\n",
        "             -0.393, -1.347, -0.185, -0.715, -1.846, -0.038, -1.242, -0.387, -0.669, -0.997,\n",
        "             -2.424, -1.103, -0.843, -0.552, -1.283, -1.026, -1.448, -0.231, -0.267, -0.769,\n",
        "             -0.341, -1.874, -1.213, -2.168, -2.116, -0.886, -1.061, -0.937, 0.576, -0.636]\n",
        "n1 = len(task1Data)\n",
        "sigma = 0.5\n",
        "alpha = -1"
      ],
      "metadata": {
        "id": "edWpFA5m-Wp5"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSampleMean():\n",
        "  sampleMean = 0\n",
        "  for number in task1Data:\n",
        "    sampleMean += number\n",
        "  return sampleMean / n1"
      ],
      "metadata": {
        "id": "flonRQ8Q_mHq"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSampleVariance(mathExpectation):\n",
        "  sampleVarience = 0\n",
        "  for number in task1Data:\n",
        "    sampleVarience += (number - mathExpectation)**2\n",
        "  return sampleVarience / n1"
      ],
      "metadata": {
        "id": "DSC1DbQcAktO"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getUnbiasedSampleVariance(mathExpectation):\n",
        "  sampleVariance = getSampleVariance(mathExpectation)\n",
        "  return sampleVariance * n1 / (n1 - 1)"
      ],
      "metadata": {
        "id": "YPu2CQNCBtq5"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\text{Сonfidence intervals:}$"
      ],
      "metadata": {
        "id": "Kkc3_G_GIDUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###$\\text{a) for} \\space\\space \\alpha, \\text{ if }\\space \\sigma^2 \\space  \\text{known;}$"
      ],
      "metadata": {
        "id": "XdKM5GqRIp5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№1$$\n",
        "$$$$\n",
        "$$\\vec{X} \\sim N_{\\alpha, \\sigma^2}$$\n",
        "$\\text{a) }\\overline{X} \\sim N_{\\alpha, \\frac{\\sigma^2}{n}}$\n",
        "\n",
        "$G(\\overline{X}, \\alpha) = \\frac{\\overline{X} - \\alpha}{\\sqrt{\\frac{\\sigma^2}{n}}} \\sim N_{0, 1} \\text{ (Theorem on the properties of normal samples)}$\n",
        "\n",
        "$P(\\alpha^{-} \\leq \\sqrt{n}\\frac{(\\overline{X} - \\alpha)}{\\sigma} \\leq \\alpha^{+}) = 1 - \\varepsilon$\n",
        "\n",
        "\\begin{cases}\n",
        "    \\phi_{0,1}(\\alpha^{-}) = \\frac{\\varepsilon}{2}\\\\\n",
        "    \\phi_{0,1}(\\alpha^{+}) = 1 - \\frac{\\varepsilon}{2}\n",
        "\\end{cases}\n",
        "\n",
        "\\begin{cases}\n",
        "    \\alpha^{-} = -\\tau_{1 - \\frac{\\varepsilon}{2}}\\\\\n",
        "    \\alpha^{+} = \\tau_{1 - \\frac{\\varepsilon}{2}}\n",
        "\\end{cases}\n",
        "\n",
        "$P(-\\tau_{1 - \\frac{\\varepsilon}{2}} \\leq \\sqrt{n}\\frac{(\\overline{X} - \\alpha)}{\\sigma} \\leq \\tau_{1 - \\frac{\\varepsilon}{2}}) = 1 - \\varepsilon$\n",
        "\n",
        "$P(\\overline{X} - \\frac{\\sigma\\tau_{1 - \\frac{\\varepsilon}{2}}}{\\sqrt{n}} \\leq \\alpha \\leq \\overline{X} + \\frac{\\sigma\\tau_{1 - \\frac{\\varepsilon}{2}}}{\\sqrt{n}}) = 1 - \\varepsilon$\n",
        "\n",
        "$\\text{Confidence interval for }\\alpha\\text{, with a known } \\sigma^2:$\n",
        "\n",
        "$$(\\overline{X} - \\frac{\\sigma\\tau_{1 - \\frac{\\varepsilon}{2}}}{\\sqrt{n}};\\overline{X} + \\frac{\\sigma\\tau_{1 - \\frac{\\varepsilon}{2}}}{\\sqrt{n}})$$\n",
        "\n"
      ],
      "metadata": {
        "id": "2R3VH1c6PqEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildConfidenceIntervalA():\n",
        "  sampleMean = getSampleMean()\n",
        "  alphaPlusArray = [norm.ppf(0.995), norm.ppf(0.975), norm.ppf(0.95)]\n",
        "  \n",
        "  for alphaPlus in alphaPlusArray:\n",
        "    leftBorder = sampleMean - math.sqrt(sigma) * alphaPlus / math.sqrt(n1)\n",
        "    rightBorder = sampleMean + math.sqrt(sigma) * alphaPlus / math.sqrt(n1)\n",
        "    print(f\"({round(leftBorder, 3)} ; {round(rightBorder, 3)})\")"
      ],
      "metadata": {
        "id": "D-ZIT-QICUWE"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###$\\text{b) for} \\space\\space \\alpha, \\text{ if }\\space \\sigma^2 \\space  \\text{unknown;}$"
      ],
      "metadata": {
        "id": "jfcf9CBpJmRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№1$$\n",
        "$$$$\n",
        "$$\\vec{X} \\sim N_{\\alpha, \\sigma^2}$$\n",
        "\n",
        "$\\text{b) }\\overline{X} \\sim N_{\\alpha, \\frac{\\sigma^2}{n}}$\n",
        "\n",
        "$G(\\overline{X}, \\alpha) = \\frac{(\\overline{X} - \\alpha)\\sqrt{n}}{S_0} \\sim T_{n - 1}\\text{ (Theorem on the properties of normal samples),   }S_0 = \\sqrt{S_0^2}$\n",
        "\n",
        "\\begin{cases}\n",
        "    T_{n - 1}(\\alpha^{-}) = \\frac{\\varepsilon}{2}\\\\\n",
        "    T_{n - 1}(\\alpha^{+}) = 1 - \\frac{\\varepsilon}{2}\n",
        "\\end{cases}\n",
        "$$\\alpha^{+} = - \\alpha^{-}$$\n",
        "\n",
        "$P(-\\alpha^{+} \\leq \\frac{(\\overline{X} - \\alpha)\\sqrt{n}}{S_0} \\leq \\alpha^{+}) = 1 - \\varepsilon$\n",
        "\n",
        "$P(\\overline{X} - \\frac{\\alpha^{+} S_0}{\\sqrt{n}} \\leq \\alpha \\leq \\overline{X} + \\frac{\\alpha^{+} S_0}{\\sqrt{n}}) = 1 - \\varepsilon$\n",
        "\n",
        "$\\text{Confidence interval for }\\alpha\\text{, with a unknown } \\sigma^2:$\n",
        "\n",
        "$$(\\overline{X} - \\frac{\\alpha^{+} S_0}{\\sqrt{n}};\\overline{X} + \\frac{\\alpha^{+} S_0}{\\sqrt{n}})$$"
      ],
      "metadata": {
        "id": "u3ryo0XqU76x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildConfidenceIntervalB():\n",
        "  sampleMean = getSampleMean()\n",
        "  unbiasedSampleVariance = getUnbiasedSampleVariance(sampleMean)\n",
        "  alphaPlusArray = [t.ppf(0.995, n1 - 1), t.ppf(0.975, n1 - 1), t.ppf(0.95, n1 - 1)]\n",
        "  for alphaPlus in alphaPlusArray:\n",
        "    leftBorder = sampleMean - alphaPlus * math.sqrt(unbiasedSampleVariance) / math.sqrt(n1)\n",
        "    rightBorder = sampleMean + alphaPlus * math.sqrt(unbiasedSampleVariance) / math.sqrt(n1)\n",
        "    print(f\"({round(leftBorder, 3)} ; {round(rightBorder, 3)})\")"
      ],
      "metadata": {
        "id": "qywezZ1xEVdt"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###$\\text{c) for} \\space\\space \\sigma^2, \\text{ if }\\space \\alpha \\space  \\text{known;}$"
      ],
      "metadata": {
        "id": "BiIC0cUPPlI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№1$$\n",
        "$$$$\n",
        "$$\\vec{X} \\sim N_{\\alpha, \\sigma^2}$$\n",
        "\n",
        "$\\text{c) }\\frac{X_i - \\alpha}{\\sigma} \\sim N_{0, 1}$\n",
        "\n",
        "$G(S, \\sigma^2) = \\sum \\limits_{i = 1}^n (\\frac{X_i - \\alpha}{\\sigma})^2 \\sim \\chi_n^2 $\n",
        "\n",
        "$P(\\alpha^{-} \\leq \\sum \\limits_{i = 1}^n (\\frac{X_i - \\alpha}{\\sigma})^2 \\leq \\alpha^{+}) = 1 - \\varepsilon$\n",
        "\n",
        "\\begin{cases}\n",
        "    \\chi_n^2(\\alpha^{-}) = \\frac{\\varepsilon}{2}\\\\\n",
        "    \\chi_n^2(\\alpha^{+}) = 1 - \\frac{\\varepsilon}{2}\n",
        "\\end{cases}\n",
        "\n",
        "$P(\\frac{\\sum \\limits_{i = 1}^n (X_i - \\alpha)^2}{\\alpha^{+}} \\leq \\sigma^2 \\leq \\frac{\\sum \\limits_{i = 1}^n (X_i - \\alpha)^2}{\\alpha^{-}}) = 1 - \\varepsilon$\n",
        "\n",
        "$\\text{Confidence interval for }\\sigma^2\\text{, with a known } \\alpha:$\n",
        "\n",
        "$$\\Biggl( \\frac{\\sum \\limits_{i = 1}^n (X_i - \\alpha)^2}{\\alpha^{+}};\\frac{\\sum \\limits_{i = 1}^n (X_i - \\alpha)^2}{\\alpha^{-}} \\Biggl)$$"
      ],
      "metadata": {
        "id": "5_0VCErCVuSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildConfidenceIntervalC():\n",
        "  S = getSampleVariance(alpha)\n",
        "  alphaPlusArray = [chi2.ppf(0.995, df = n1), chi2.ppf(0.975, df = n1), chi2.ppf(0.95, df = n1)]\n",
        "  alphaMinusArray = [chi2.ppf(0.005, df = n1), chi2.ppf(0.025, df = n1), chi2.ppf(0.05, df = n1)]\n",
        "  for i in range(3):\n",
        "    leftBorder = n1 * S / alphaPlusArray[i]\n",
        "    rightBorder = n1 * S / alphaMinusArray[i]\n",
        "    print(f\"({round(leftBorder, 3)} ; {round(rightBorder, 3)})\")"
      ],
      "metadata": {
        "id": "8gfJ0dsyJVgz"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###$\\text{d) for} \\space\\space \\sigma^2, \\text{ if }\\space \\alpha \\space  \\text{unknown;}$"
      ],
      "metadata": {
        "id": "z7VxeN3AP1Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№1$$\n",
        "$$$$\n",
        "$$\\vec{X} \\sim N_{\\alpha, \\sigma^2}$$\n",
        "$\\text{d) }S^2 = \\frac{1}{n}\\sum \\limits_{i = 1}^n (X_i - \\overline{X})^2$\n",
        "\n",
        "$G(S^2, \\sigma^2) = \\frac{nS^2}{\\sigma^2} \\sim \\chi_{n-1}^2 \\text{ (Theorem on the properties of normal samples)}$\n",
        "\n",
        "$P(\\alpha^{-} \\leq \\frac{nS^2}{\\sigma^2} \\leq \\alpha^{+}) = 1 - \\varepsilon$\n",
        "\n",
        "\\begin{cases}\n",
        "    \\chi_{n - 1}^2(\\alpha^{-}) = \\frac{\\varepsilon}{2}\\\\\n",
        "    \\chi_{n - 1}^2(\\alpha^{+}) = 1 - \\frac{\\varepsilon}{2}\n",
        "\\end{cases}\n",
        "\n",
        "$P(\\frac{nS^2}{\\alpha^{+}} \\leq \\sigma^2 \\leq \\frac{nS^2}{\\alpha^{-}}) = 1 - \\varepsilon$\n",
        "\n",
        "$\\text{Confidence interval for }\\sigma^2\\text{, with a unknown } \\alpha:$\n",
        "\n",
        "$$(\\frac{nS^2}{\\alpha^{+}};\\frac{nS^2}{\\alpha^{-}})$$"
      ],
      "metadata": {
        "id": "hOPvpThvWbIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildConfidenceIntervalD():\n",
        "  sampleMean = getSampleMean()\n",
        "  sampleVariance = getSampleVariance(sampleMean)\n",
        "  alphaPlusArray = [chi2.ppf(0.995, df = n1 - 1), chi2.ppf(0.975, df = n1 - 1), chi2.ppf(0.95, df = n1 - 1)]\n",
        "  alphaMinusArray = [chi2.ppf(0.005, df = n1 - 1), chi2.ppf(0.025, df = n1 - 1), chi2.ppf(0.05, df = n1 - 1)]\n",
        "  for i in range(3):\n",
        "    leftBorder = n1 * sampleVariance / alphaPlusArray[i]\n",
        "    rightBorder = n1 * sampleVariance / alphaMinusArray[i]\n",
        "    print(f\"({round(leftBorder, 3)} ; {round(rightBorder, 3)})\")"
      ],
      "metadata": {
        "id": "pKFgoUeoNrAV"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from scipy.stats import kstwobign as klm"
      ],
      "metadata": {
        "id": "8d2V_X3xb6MB"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$\\text{Second:}$"
      ],
      "metadata": {
        "id": "epiRq850nfI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "task2Data = [0.041, 0.234, 0.279, 0.654, 0.297, 0.667, 0.044, 0.701, 0.710, 0.952,\n",
        "             0.298, 0.795, 0.618, 0.377, 0.222, 0.269, 0.626, 0.348, 0.503, 0.630,\n",
        "             0.335, 0.975, 0.973, 0.169, 0.596, 0.288, 0.353, 0.124, 0.530, 0.239]\n",
        "a = 0\n",
        "b = 1\n",
        "n2 = len(task2Data)\n",
        "epsilon = 0.05"
      ],
      "metadata": {
        "id": "9QRdP47ZZ-r1"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\text{a) Empirical function and histogram;}$"
      ],
      "metadata": {
        "id": "kc8YGo4tQIZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№2$$\n",
        "$$$$\n",
        "$$\\vec{X} \\sim U_{[0,1]}$$\n",
        "\n",
        "$\\text{a) Empirical function:}$\n",
        "\n",
        "$$F_n^*(t) = \\frac{1}{n}\\sum \\limits_{i = 1}^nI(X_i < t),\\space\\space I(A) = \n",
        "\\begin{cases}\n",
        "  1, w \\in A\\\\\n",
        "  0, w \\notin A\n",
        "\\end{cases}$$"
      ],
      "metadata": {
        "id": "ZSKYDdDfk7l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drawEmpiricalFunction():\n",
        "  sns.ecdfplot(data = task2Data, c = \"green\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4k1mCyt_bpLf"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$k = log_2(n) + 1\\space(\\text{The Sturgess Rule})$$"
      ],
      "metadata": {
        "id": "xjWGtNUWG5Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drawHistogram():\n",
        "  plt.hist(task2Data, density = True, edgecolor = \"black\", color = \"green\", bins = int(math.log2(n2) + 1))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rmytweBrnxJd"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\text{b) Kolmogorov criterion;}$"
      ],
      "metadata": {
        "id": "d5exYoajQk7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№2$$\n",
        "$$$$\n",
        "$$\\vec{X} \\sim U_{[0,1]}$$\n",
        "$$\\begin{cases}\n",
        "  H_o = \\{F \\stackrel{d}{=} U_{[0, 1]}\\}, \\space(\\text{simple hypothesis})\\\\\n",
        "  H_a = \\{F \\stackrel{d}{\\neq} U_{[0, 1]}\\}\n",
        "\\end{cases}$$\n",
        "\n",
        "$\\text{b) Kolmogorov distance:}$\n",
        "\n",
        "$$d(F_n^*(t), F_o(t)) = \\underset{t \\in \\mathbb{R}}{sup}|F_n^*(t) - F_o(t)|$$\n",
        "\n",
        "$\\text{Kolmogorov's criterion:}$\n",
        "\n",
        "$$P(\\sqrt{n}\\space d < c) \\simeq K(c) = 1 - \\varepsilon, \\space\\space c > 0$$\n",
        "\n",
        "$$\\delta = \n",
        "\\begin{cases}\n",
        "  0, \\sqrt{n}\\space d < c\\\\\n",
        "  1, \\sqrt{n}\\space d \\geq c\n",
        "\\end{cases}, \\space\\space K(c) = 1 - \\varepsilon$$"
      ],
      "metadata": {
        "id": "8TE0B76ibqU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indicator(number, t):\n",
        "  return number < t"
      ],
      "metadata": {
        "id": "rSElzA_B_9cs"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def empiricalFunc(t):\n",
        "  sum = 0\n",
        "  for number in task2Data:\n",
        "    sum += indicator(number, t)\n",
        "  return sum / n2"
      ],
      "metadata": {
        "id": "MTVYjMs9AVya"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drawKolmogorovCriterion():\n",
        "  sns.ecdfplot(data = task2Data, c = \"green\")\n",
        "  x = [0, 1]\n",
        "  y = [0, 1]\n",
        "  temp_df = pd.DataFrame(x, y)\n",
        "  sns.lineplot(data = temp_df)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "z0CLAM6KlGOj"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kolmogorovCriterion():\n",
        "  x = np.linspace(0, 1, 10000)\n",
        "  y = lambda x: empiricalFunc(x)\n",
        "  z = lambda x: x\n",
        "\n",
        "  point = 0\n",
        "  d = 0\n",
        "\n",
        "  for x_ in x:\n",
        "    if (abs(y(x_) - z(x_)) > d):\n",
        "      d = abs(y(x_) - z(x_))\n",
        "      point = x_  \n",
        "  print(\"Kolmogorov distance : \", round((n2) ** (1 / 2) * d, 3))\n",
        "  print(\"Point : \", round(point, 3))\n",
        "\n",
        "  c = klm.ppf(1 - epsilon)\n",
        "  print(\"c = \", round(c, 3))\n",
        "  if (math.sqrt(n2) * d < c):\n",
        "    print(\"The hypothesis is accepted!\")\n",
        "  else:\n",
        "    print(\"The hypothesis is not accepted!\")"
      ],
      "metadata": {
        "id": "Htbl1vLrK0Ub"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\text{c)} \\space \\chi^2 \\space \\text{criterion;}$ "
      ],
      "metadata": {
        "id": "gkr9M3jyQv_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№2$$\n",
        "$$\\vec{X} \\sim U_{[0, 1]}$$\n",
        "$$\\begin{cases}\n",
        "  H_o = \\{F \\stackrel{d}{=} U_{[0, 1]}\\}, \\space(\\text{simple hypothesis})\\\\\n",
        "  H_a = \\{F \\stackrel{d}{\\neq} U_{[0, 1]}\\}\n",
        "\\end{cases}$$\n",
        "$\\text{c)}\\space\\chi^2 \\space \\text{distance:}$\n",
        "\n",
        "$$d(F_n^*, F_o) = \\sum_\\limits{j = 1}^k \\frac{(\\nu_j - np_j)^2}{np_j},$$ \n",
        "\n",
        "$$\\nu_j = \\sum_\\limits{i = 1}^nI(X_i \\in \\Delta_j),$$\n",
        "\n",
        "$$(\\Delta_1,\\space\\cdots\\space,\\Delta_k),\\space \\Delta_j = [t_j\\space;\\space t_{j + 1})$$\n",
        "\n",
        "$$p_j = P_{H_o}(X_i \\in \\Delta_j) = F_o(t_{j+1}) - F_o(t_j),$$\n",
        "\n",
        "$\\chi^2 \\space \\text{criterion:}$\n",
        "\n",
        "$$\\delta = \n",
        "\\begin{cases}\n",
        "  0, d(F_n^*, F_o) < c\\\\\n",
        "  1, d(F_n^*, F_o) \\geq c\n",
        "\\end{cases}, \\space\\space \\chi_{k - 1}^2(c) = 1 - \\varepsilon$$"
      ],
      "metadata": {
        "id": "vY6CUPmAgTs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chiSquareCriterion():\n",
        "  k = 5\n",
        "  delta = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "  p = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
        "  c = chi2.ppf(1 - epsilon, k - 1)\n",
        "  nu = [0, 0, 0, 0, 0]\n",
        "  for j in range(k):\n",
        "    for number in task2Data:\n",
        "      if (number > delta[j] and number < delta[j + 1]):\n",
        "        nu[j] += 1\n",
        "\n",
        "  d = 0\n",
        "  for j in range(k):\n",
        "    d += ((nu[j] - n2 * p[j]) ** 2) / (n2 * p[j])\n",
        "  \n",
        "  print(\"'Chi-square' distance = \", round(d, 3))\n",
        "  print(\"c = \", round(c, 3))\n",
        "\n",
        "  if (d < c):\n",
        "    print(\"The hypothesis is accepted!\")\n",
        "  else:\n",
        "    print(\"The hypothesis is not accepted!\")\n"
      ],
      "metadata": {
        "id": "Qk36LMr7Gr7A"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$\\text{Third:}$"
      ],
      "metadata": {
        "id": "AOXM9W6WBmYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.distributions import f"
      ],
      "metadata": {
        "id": "dzQDmDAcTdgB"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task3_1Data = [-1.135, -0.592, -0.766, -1.177, -0.735, -1.717, 0.336, -1.140, -0.155, -2.048,\n",
        "               -1.137, -2.147, -0.313, -0.056, -0.286, -0.829, -0.290, -0.639, -1.397, 0.362]\n",
        "\n",
        "task3_2Data = [-0.393, -1.347, -0.185, -0.715, -1.846, -0.038, -1.242, -0.387, -0.669, -0.997,\n",
        "               -2.424, -1.103, -0.843, -0.552, -1.283, -1.026, -1.448, -0.231, -0.267, -0.769,\n",
        "               -0.341, -1.874, -1.213, -2.168, -2.116, -0.886, -1.061, -0.937, 0.576, -0.636]\n",
        "               \n",
        "n3_1 = len(task3_1Data)\n",
        "n3_2 = len(task3_2Data)"
      ],
      "metadata": {
        "id": "ZoTU_P-0Rvls"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\text{a) Testing the hypothesis of matching variances (Fisher's criterion);}$"
      ],
      "metadata": {
        "id": "eTr775f2RTWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№3$$\n",
        "$$$$\n",
        "$$\\text{a)} \\space \\left. \\begin{gathered}\n",
        "  \\vec{X} \\sim N_{\\alpha_1, \\sigma_1^2}\\\\\n",
        "  \\vec{Y} \\sim N_{\\alpha_2, \\sigma_2^2}\n",
        "\\end{gathered}\\right\\} \\space \\text{Independet}$$\n",
        "\n",
        "$$\\begin{cases}\n",
        "  H_o = \\{\\sigma_1^2 = \\sigma_2^2\\}\\\\\n",
        "  H_a = \\{\\sigma_1^2 \\neq \\sigma_2^2\\}\n",
        "\\end{cases}$$\n",
        "\n",
        "$\\text{Fisher's criterion:}$\n",
        "\n",
        "$$\\text{Independent}\\begin{cases}\n",
        "  \\frac{nS^2(\\vec{X})}{\\sigma_1^2} \\sim \\chi_{n - 1}^2\\\\\n",
        "  \\frac{nS^2(\\vec{Y})}{\\sigma_2^2} \\sim \\chi_{m - 1}^2\n",
        "\\end{cases} \\Longrightarrow\n",
        "\\frac{\\frac{nS^2(\\vec{X})}{\\sigma_1^2(n - 1)}}{\\frac{mS^2(\\vec{Y})}{\\sigma_2^2(m - 1)}} = \\frac{S_0^2(\\vec{X}) \\sigma_2^2}{S_0^2(\\vec{Y})\\sigma_1^2} \\sim F_{n - 1, m - 1}$$\n",
        "\n",
        "$\\text{Empirical significance of the Fisher criterion:}$\n",
        "\n",
        "$$d = \\frac{S_0^2(\\vec{X})}{S_0^2(\\vec{Y})} \\space \\stackrel{H_o}{\\sim} \\space F_{n - 1, m - 1}$$\n",
        "$$$$\n",
        "$$\\delta = \n",
        "\\begin{cases}\n",
        "  0, \\space f_1 < \\frac{S_0^2(\\vec{X})}{S_0^2(\\vec{Y})} < f_2\\\\\n",
        "  1, \\space otherwise\n",
        "\\end{cases}$$\n",
        "$$$$\n",
        "$$\\begin{cases}\n",
        "  F_{n - 1, m - 1}(f_1) = \\frac{\\varepsilon}{2}\\\\\n",
        "  F_{n - 1, m - 1}(f_2) = 1 - \\frac{\\varepsilon}{2}\n",
        "\\end{cases}$$"
      ],
      "metadata": {
        "id": "Perv33W2nTL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def varianceHypothesis():\n",
        "  f1 = f.ppf(epsilon / 2, n3_1 - 1, n3_2 - 1)\n",
        "  f2 = f.ppf(1 - epsilon / 2, n3_1 - 1, n3_2 - 1)\n",
        "  sampleMean1 = 0\n",
        "  sampleMean2 = 0\n",
        "\n",
        "  unbiasedSampleVariace1 = 0\n",
        "  unbiasedSampleVariace2 = 0\n",
        "  for number in task3_1Data:\n",
        "    sampleMean1 += number / n3_1\n",
        "\n",
        "  for number in task3_2Data:\n",
        "    sampleMean2 += number / n3_2\n",
        "\n",
        "  for number in task3_1Data:\n",
        "    unbiasedSampleVariace1 += (number - sampleMean1) ** 2 / (n3_1 - 1)\n",
        "\n",
        "  for number in task3_2Data:\n",
        "    unbiasedSampleVariace2 += (number - sampleMean2) ** 2 / (n3_2 - 1)\n",
        "\n",
        "    d = unbiasedSampleVariace1 / unbiasedSampleVariace2\n",
        "\n",
        "  print(\"Sample mean 1 = \", round(sampleMean1, 3))\n",
        "  print(\"Sample mean 2 = \", round(sampleMean2, 3))\n",
        "\n",
        "  print(\"Empirical significance of the Fisher criterion = \", round(d, 3))\n",
        "  print(\"f_1 = \", round(f1, 3))\n",
        "  print(\"f_2 = \", round(f2, 3))\n",
        "\n",
        "  if (f1 < d < f2):\n",
        "    print(\"The variances are equal!\")\n",
        "  else:\n",
        "    print(\"The variances are not equal!\")\n"
      ],
      "metadata": {
        "id": "cFzd2Df8Q4Jx"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\text{b) Testing the hypothesis of the coincidence of mathematical expectations with the same variances (Student's criterion):}$"
      ],
      "metadata": {
        "id": "8cmoEZzIRmH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$№3$$\n",
        "$$$$\n",
        "$$\\begin{cases}\n",
        "  H_o = \\{\\alpha_1 = \\alpha_2\\}\\\\\n",
        "  H_a = \\{\\alpha_1 \\neq \\alpha_2\\}\n",
        "\\end{cases}$$\n",
        "$$\\text{b)  Independet} \\space\n",
        "\\begin{cases}\n",
        "  \\frac{nS^2(\\vec{X})}{\\sigma_1^2} \\sim \\chi_{n - 1}^2\\\\\n",
        "  \\frac{nS^2(\\vec{Y})}{\\sigma_2^2} \\sim \\chi_{m - 1}^2\n",
        "\\end{cases} \\underset{\\text{stable by} \\sum}{\\Longrightarrow} \\frac{nS^2(\\vec{X}) + mS^2(\\vec{Y})}{(\\sigma_1 = \\sigma_2)^2} \\sim \\chi_{m + n - 2}^2$$\n",
        "\n",
        "$$\\overline{X} - \\overline{Y} \\sim N_{\\alpha_1 - \\alpha_2, \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m}}$$\n",
        "\n",
        "$$E(\\overline{X} - \\overline{Y}) = E(X_1) - E(Y_1) = \\alpha_1 - \\alpha_2$$\n",
        "\n",
        "$$D(\\overline{X} - \\overline{Y}) \\stackrel{independet}{=} D\\overline{X} + D\\overline{Y} = \\frac{DX_1}{n} + \\frac{DY_1}{m}$$\n",
        "$$$$\n",
        "$\\text{Student's criterion:}$\n",
        "$$$$\n",
        "$$\\frac{\\frac{(\\overline{X} - \\overline{Y}) - (\\alpha_1 - \\alpha_2)}{\\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}}}}{\\sqrt{\\frac{nS^2(\\vec{X}) + mS^2(\\vec{Y})}{\\sigma^2(m + n - 2)}}} = \\frac{\\big((\\overline{X} - \\overline{Y}) - (\\alpha_1 - \\alpha_2)\\big) \\sqrt{(m + n - 2)mn}}{\\sqrt{\\big(nS^2(\\vec{X}) + mS^2(\\vec{Y})\\big)(n + m)}} \\sim T_{n + m - 2}$$\n",
        "\n",
        "$$d = \\frac{\\big((\\overline{X} - \\overline{Y}) - (\\alpha_1 - \\alpha_2)\\big)\\sqrt{(m + n - 2)mn}}{\\sqrt{\\big(nS^2(\\vec{X}) + mS^2(\\vec{Y}) \\big) (n + m)}} \\space\\stackrel{H_o}{=}\\space \n",
        "\\frac{(\\overline{X} - \\overline{Y}) \\sqrt{(m + n - 2)mn}}{\\sqrt{\\big(nS^2(\\vec{X}) + mS^2(\\vec{Y}) \\big) (n + m)}} \\sim T_{n + m - 2}$$\n",
        "\n",
        "$$\\delta = \n",
        "\\begin{cases}\n",
        "  0, |d| < t_{1 - \\frac{\\varepsilon}{2}}\\\\\n",
        "  1, otherwise\n",
        "\\end{cases},\\space T_{m + n - 2}(t_{1 - \\frac{\\varepsilon}{2}}) = 1 - \\frac{\\varepsilon}{2}$$"
      ],
      "metadata": {
        "id": "m8p7ixeRjnNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mathExpectationHypothesis():\n",
        "  sampleMean1 = 0\n",
        "  sampleMean2 = 0\n",
        "\n",
        "  sampleVariace1 = 0\n",
        "  sampleVariace2 = 0\n",
        "\n",
        "  for number in task3_1Data:\n",
        "    sampleMean1 += number / n3_1\n",
        "\n",
        "  for number in task3_2Data:\n",
        "    sampleMean2 += number / n3_2\n",
        "\n",
        "  for number in task3_1Data:\n",
        "    sampleVariace1 += (number - sampleMean1) ** 2 / n3_1\n",
        "\n",
        "  for number in task3_2Data:\n",
        "    sampleVariace2 += (number - sampleMean2) ** 2 / n3_2\n",
        "\n",
        "  d = (sampleMean1 - sampleMean2) * math.sqrt((n3_1 + n3_2 - 2) * n3_1 * n3_2) \n",
        "  d /= math.sqrt((n3_1 * sampleVariace1 + n3_2 * sampleVariace2) * (n3_1 + n3_2))\n",
        "  c = t.ppf(1 - epsilon / 2, n3_1 + n3_2 - 2)\n",
        "\n",
        "  print(\"d = \", round(d, 3))\n",
        "  print(\"c = \", round(c, 3))\n",
        "\n",
        "  if (abs(d) < c):\n",
        "    print(\"The mathematical expectation are equal!\")\n",
        "  else:\n",
        "    print(\"The mathematical expectation are not equal!\")"
      ],
      "metadata": {
        "id": "23XrlBW7BByv"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$\\text{Results:}$"
      ],
      "metadata": {
        "id": "XB2dAApyMx1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Task #1\")\n",
        "print(\"====================\")\n",
        "print(\"A:\")\n",
        "buildConfidenceIntervalA()\n",
        "print(\"====================\")\n",
        "print(\"B:\")\n",
        "buildConfidenceIntervalB()\n",
        "print(\"====================\")\n",
        "print(\"C:\")\n",
        "buildConfidenceIntervalC()\n",
        "print(\"====================\")\n",
        "print(\"D:\")\n",
        "buildConfidenceIntervalD()\n",
        "print(\"====================\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9833o7fvD_fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Task #2\")\n",
        "print(\"Empirical function:\")\n",
        "%matplotlib widget\n",
        "drawEmpiricalFunction()"
      ],
      "metadata": {
        "id": "H-_sMPfAjCEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nHistogram:\")\n",
        "%matplotlib widget\n",
        "drawHistogram()"
      ],
      "metadata": {
        "id": "ozyfuSXdivO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Kolmogorov's criterion graph:\")\n",
        "%matplotlib widget\n",
        "drawKolmogorovCriterion()\n",
        "kolmogorovCriterion()"
      ],
      "metadata": {
        "id": "GXBy03qVhfr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chiSquareCriterion()"
      ],
      "metadata": {
        "id": "TCtFncInSXww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Task #3\")\n",
        "varianceHypothesis()\n",
        "mathExpectationHypothesis()"
      ],
      "metadata": {
        "id": "Rug6LsYrfcSY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}